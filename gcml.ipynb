{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3155a860-8dce-4ba8-8ab8-6c0af1c06884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c65782f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate a random graph\n",
    "def construct_random_subgraph(num_nodes, min_edges=2, max_edges=5):\n",
    "    min_edges-=1\n",
    "    max_edges-=1\n",
    "    connections = np.random.uniform(size=(num_nodes, num_nodes))\n",
    "    connections += np.roll(np.eye(num_nodes), 1, 1)  # make sure every node is connected\n",
    "    connections -= np.eye(num_nodes)  # make sure no self-connections\n",
    "    # set strongest connections\n",
    "    sorted_connections = np.sort(connections)[:, ::-1]\n",
    "    min_edges = min_edges\n",
    "    max_edges = max_edges + 1\n",
    "    min_edges = int(min_edges / 2 + 0.5)  # used to be min_edges // 2\n",
    "    max_edges = int(max_edges / 2 + 0.5)\n",
    "    indices = np.stack([np.arange(num_nodes), np.random.randint(min_edges, max_edges, num_nodes)])\n",
    "    thresholds = sorted_connections[indices[0], indices[1]]\n",
    "    connections = np.where(connections > thresholds[:, None], 1., 0.).astype(np.float32)\n",
    "    connections = np.clip(connections + connections.T, 0, 1)\n",
    "    return connections\n",
    "\n",
    "# function to generate a random small world graph\n",
    "def construct_small_world_graph(n_nodes_per_world=6, n_worlds=4):\n",
    "    n_nodes = n_nodes_per_world * n_worlds\n",
    "    connections = np.zeros((n_nodes, n_nodes))\n",
    "    for world_i in range(n_worlds):\n",
    "        connection = construct_random_subgraph(n_nodes_per_world)\n",
    "        # add to global graph\n",
    "        start_i = world_i * n_nodes_per_world\n",
    "        end_i = (world_i+1) * n_nodes_per_world\n",
    "        connections[start_i:end_i, start_i:end_i] = connection\n",
    "        # connect to graph\n",
    "        if world_i != 0:\n",
    "            node_from = np.random.randint(start_i, end_i)\n",
    "            node_to = node_from - n_nodes_per_world\n",
    "            connections[node_from, node_to] = 1\n",
    "            connections[node_to, node_from] = 1\n",
    "    return connections\n",
    "\n",
    "# function to generate a dead ends graph\n",
    "def construct_dead_ends_graph():\n",
    "    # construct the shell-like connectivity\n",
    "    n_shells = 4\n",
    "    n_neurons_per_shell = 6\n",
    "    layers_with_circular_connection = [1]\n",
    "    size = n_shells * n_neurons_per_shell\n",
    "    connections = np.zeros((size, size)).astype(np.float32)\n",
    "    eye = np.eye(n_neurons_per_shell)\n",
    "    for i in range(n_shells):\n",
    "        if i in layers_with_circular_connection:\n",
    "            # add circular connection\n",
    "            idx = i * n_neurons_per_shell\n",
    "            connections[idx:idx+n_neurons_per_shell, idx:idx+n_neurons_per_shell] = np.roll(eye, 1, axis=1)\n",
    "\n",
    "        # add connections to next shell\n",
    "        if i + 1 < n_shells:\n",
    "            # connect to outer shell\n",
    "            idx = i * n_neurons_per_shell\n",
    "            j = idx + n_neurons_per_shell\n",
    "            connections[idx:idx+n_neurons_per_shell, j:j+n_neurons_per_shell] = eye\n",
    "\n",
    "    connections = connections + connections.T\n",
    "    return connections\n",
    "\n",
    "# function to generate a grid graph with numerical paths to move to a target\n",
    "def construct_grid_graph():\n",
    "    n = 4\n",
    "    l = 5\n",
    "    n_nodes = n * l + l // 2\n",
    "\n",
    "    tmp_n_nodes = 0\n",
    "    layer_index_bounds = []\n",
    "    for i in range(l):\n",
    "        tmp_n_nodes += n if i % 2 == 0 else n + 1\n",
    "        layer_index_bounds.append(tmp_n_nodes)\n",
    "\n",
    "    connections = []\n",
    "\n",
    "    lower_idx = 0\n",
    "    for layer_idx in range(l):\n",
    "        upper_idx = layer_index_bounds[layer_idx]\n",
    "        for i in range(lower_idx, upper_idx):\n",
    "            if i + 1 < upper_idx:\n",
    "                connections.append([i, i + 1])\n",
    "            if layer_idx + 1 < l:\n",
    "                # not last layer\n",
    "                next_upper_idx = layer_index_bounds[layer_idx+1]\n",
    "                dist1 = n if layer_idx % 2 == 0 else n + 1\n",
    "                dist2 = n + 1 if layer_idx % 2 == 0 else n\n",
    "                if upper_idx <= i + dist1 < next_upper_idx:\n",
    "                    connections.append([i, i + dist1])\n",
    "                if upper_idx <= i + dist2 < next_upper_idx:\n",
    "                    connections.append([i, i + dist2])\n",
    "        lower_idx = upper_idx\n",
    "    connections = np.array(connections)\n",
    "    i, j = connections.T\n",
    "    adj = np.zeros((n_nodes, n_nodes))\n",
    "    adj[i, j] = 1\n",
    "    adj += adj.T\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "066d9e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], dtype=torch.int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 1, (0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f50ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset of trajectories\n",
    "class RandomWalkDataset(Dataset):\n",
    "    def __init__(self, adj_matrix, trajectory_length, num_trajectories, n_items):\n",
    "        self.n_items = n_items\n",
    "        self.adj_matrix = adj_matrix\n",
    "        self.num_trajectories = num_trajectories\n",
    "        self.trajectory_length = trajectory_length\n",
    "        self.edges, self.action_indices = edges_from_adjacency(adj_matrix)\n",
    "        #start_nodes = torch.randint(0, adj_matrix.size(0), (num_trajectories,)).tolist()\n",
    "        start_nodes = [torch.randint(0, adj_matrix.size(0), (1,)).tolist()[0]] * num_trajectories # same start node for all\n",
    "        self.data = []\n",
    "        for node in start_nodes:\n",
    "            items = (torch.rand(self.adj_matrix.shape[0]) * self.n_items).to(torch.int32)\n",
    "            trajectory = strict_random_walk(self.adj_matrix, node, self.trajectory_length, self.action_indices, items)\n",
    "            self.data.append(torch.tensor([(x[0], x[1], x[2]) for x in trajectory]))\n",
    "    def __len__(self):\n",
    "        return self.num_trajectories  # Number of trajectories\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    \n",
    "# function to generate random walk trajectories on a given graph\n",
    "def strict_random_walk(adj_matrix, start_node, length, action_indices, items):\n",
    "    current_node = start_node\n",
    "    trajectory = []\n",
    "    for _ in range(length - 1):  # subtract 1 to account for the start node\n",
    "        neighbors = torch.where(adj_matrix[current_node] > 0)[0].tolist()\n",
    "        if not neighbors:\n",
    "            break\n",
    "        next_node = neighbors[torch.randint(0, len(neighbors), (1,)).item()]\n",
    "        trajectory.append((items[current_node], action_indices[(current_node, next_node)], items[next_node]))\n",
    "        current_node = next_node\n",
    "    return trajectory\n",
    "\n",
    "# indexing each action for a given adjacency matrix\n",
    "def edges_from_adjacency(adj_matrix):\n",
    "    # The input is a given random matrix's adjacency matrix\n",
    "    # The outputs are:\n",
    "        # edges: a list of pairs of (start node, end node) for each action\n",
    "        # action_indices: a dictionary, each key is a pair of(start node, end node),\n",
    "            # and its corresponding value is this action's index\n",
    "    # For a pure on-line algorithm, this can also be done by assigning index to unseen actions\n",
    "    # during random-walk on-line\n",
    "    n = adj_matrix.shape[0]\n",
    "    edges = []\n",
    "    action_idx = 0\n",
    "    action_indices = {}\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):  # Only upper triangle\n",
    "            if adj_matrix[i][j] != 0:\n",
    "                edges.append((i, j))\n",
    "                action_indices[(i, j)] = action_idx\n",
    "                action_idx += 1\n",
    "                edges.append((j, i))\n",
    "                action_indices[(j, i)] = action_idx\n",
    "                action_idx += 1\n",
    "    return edges, action_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb91ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEnv:\n",
    "    def __init__(self, size=32, n_items=10, env='random', batch_size=15, num_desired_trajectories=10, device=None):\n",
    "        if env == 'random':\n",
    "            self.adj_matrix = construct_random_subgraph(size, 2, 5)\n",
    "        elif env == 'small world':\n",
    "            self.adj_matrix = construct_small_world_graph()\n",
    "        elif env == 'dead ends':\n",
    "            self.adj_matrix = construct_dead_ends_graph()\n",
    "        elif env == 'grid':\n",
    "            self.adj_matrix = construct_grid_graph()\n",
    "        self.adj_matrix = torch.tensor(self.adj_matrix)\n",
    "        self.size = self.adj_matrix.shape[0]\n",
    "        self.affordance, self.node_to_action_matrix,\\\n",
    "        self.action_to_node = node_outgoing_actions(self.adj_matrix)\n",
    "        \n",
    "        self.affordance = {k: torch.tensor(v).to(device)\\\n",
    "                           for k, v in self.affordance.items()}\n",
    "        self.node_to_action_matrix = self.node_to_action_matrix.to(device)\n",
    "        self.action_to_node = {k: torch.tensor(v).to(device) \\\n",
    "                            for k, v in self.action_to_node.items()}\n",
    "        \n",
    "        self.n_items = n_items\n",
    "        self.batch_size = batch_size\n",
    "        self.num_desired_trajectories = num_desired_trajectories\n",
    "        self.populate_graph()\n",
    "        self.gen_dataset()\n",
    "\n",
    "    # uniformly random observations\n",
    "    def populate_graph(self):\n",
    "        self.items = (torch.rand(self.size) * self.n_items).to(torch.int32)\n",
    "\n",
    "    def gen_dataset(self):\n",
    "        self.dataset = RandomWalkDataset(self.adj_matrix, self.batch_size,\n",
    "                                         self.num_desired_trajectories, self.n_items)\n",
    "        self.n_actions = len(self.dataset.action_indices)\n",
    "        \n",
    "def node_outgoing_actions(adj_matrix):\n",
    "    # This function creates several look-up tables for later computation's convecience\n",
    "    edges, action_indices = edges_from_adjacency(adj_matrix)\n",
    "    # Use an action index as a key, retrieve its (start node, end node)\n",
    "    inverse_action_indices = {v: k for k, v in action_indices.items()}\n",
    "    # Given a node as a key, retrieve all of its available outgoing actions' indexes.\n",
    "    node_actions = {}\n",
    "    # Given a pair of (start node, end node), get the action index.\n",
    "    # Since a index can be 0, this matrix is initialized to be a all -1.\n",
    "    node_to_action_matrix = -1*torch.ones_like(adj_matrix)\n",
    "    for edge in edges:\n",
    "        node_from, node_to = edge\n",
    "        if node_from not in node_actions:\n",
    "            node_actions[node_from] = []\n",
    "        node_actions[node_from].append(action_indices[edge])\n",
    "        node_to_action_matrix[node_from][node_to] = action_indices[edge]  \n",
    "    return node_actions, node_to_action_matrix.long(), inverse_action_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8745c2d0-9296-4779-b254-8c5e8820ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(torch.nn.Module):\n",
    "    def __init__(self, o_size, a_size, z_size, s_dim, device=None):\n",
    "        super(Agent, self).__init__()\n",
    "        self.Q = torch.nn.Parameter(1*torch.randn(s_dim, o_size, device=device))\n",
    "        self.V = torch.nn.Parameter(0.1*torch.randn(s_dim, a_size, device=device))\n",
    "        self.Z = torch.nn.Parameter(0.1*torch.randn(s_dim, z_size, device=device))\n",
    "        self.W = torch.nn.Parameter(0.1*torch.randn(a_size, s_dim, device=device))\n",
    "        self.o_size = o_size\n",
    "        self.a_size = a_size\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, o_pre, action, o_next):\n",
    "        prediction_error = self.Q[:,o_next]-(self.Q[:,o_pre]+self.V[:,action])\n",
    "        return prediction_error\n",
    "    \n",
    "    def plan(self, start, goal, env, weight=False):\n",
    "        a_record = []\n",
    "        o_record = []\n",
    "        loc = int(start)\n",
    "        length = 0\n",
    "        for i in range(self.o_size):\n",
    "            o_record.append(loc)\n",
    "            if loc==goal:\n",
    "                if weight:\n",
    "                    return length, o_record\n",
    "                else:\n",
    "                    return i, o_record\n",
    "            loc, action = self.move_one_step(loc, goal, a_record, env.affordance[loc], \n",
    "                    env.action_to_node, env.node_to_action_matrix[loc], weight)\n",
    "            a_record.append(action)\n",
    "            if weight:\n",
    "                length += w_connection[o_record[-1],loc]\n",
    "\n",
    "        if weight:\n",
    "            return length, o_record\n",
    "        else:\n",
    "            return i, o_record\n",
    "        \n",
    "    def move_one_step(self, loc, goal, a_record, affordance, action_to_node,\n",
    "                      next_node_to_action, weight=False, w_connection=None):  \n",
    "        affordance_vector = torch.zeros(self.a_size, device=self.device)\n",
    "        affordance_vector[affordance] = 1\n",
    "        if weight:    \n",
    "            for a in affordance:\n",
    "                a = a.item()\n",
    "                affordance_vector[a]/=(w_connection[action_to_node[a][0],\n",
    "                                                    action_to_node[a][1]])\n",
    "        affordance_vector_fix = affordance_vector.clone()\n",
    "        not_recommended_actions = a_record\n",
    "        affordance_vector_fix[not_recommended_actions] *= 0.\n",
    "\n",
    "        delta = self.Q[:,goal]-self.Q[:,loc]\n",
    "        utility = (self.W@delta) * affordance_vector_fix\n",
    "        if torch.max(utility)!=0:\n",
    "            action_idx = torch.argmax(utility).item()\n",
    "        else:\n",
    "            utility = (self.V.T@delta) * affordance_vector\n",
    "            action_idx = torch.argmax(utility).item()\n",
    "\n",
    "            \n",
    "        return action_to_node[action_idx][1].item(), action_idx\n",
    "\n",
    "class PartiallyObservableCML(torch.nn.Module):\n",
    "    def __init__(self, n_states, n_obs, n_act, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.n_states = n_states\n",
    "        self.n_obs = n_obs\n",
    "        self.n_act = n_act\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.U = torch.nn.Parameter(torch.randn(embedding_dim, n_obs), requires_grad=False)\n",
    "        self.Q = torch.nn.Parameter(torch.randn(embedding_dim, n_states))\n",
    "        self.V = torch.nn.Parameter(torch.randn(embedding_dim, n_act))\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    # assume we start in the same state every time\n",
    "    def reset(self):\n",
    "        self.M = torch.zeros(self.embedding_dim, self.embedding_dim)\n",
    "        self.z = self.Q[:, 0] # arbitrary state selection\n",
    "\n",
    "    def forward(self, o, a, o_next):\n",
    "        print(a.shape, self.z.shape, self.V[:, a].shape)\n",
    "        z_pred = self.z.detach() + self.V[:, a]\n",
    "        z_next = self.closest_state(z_pred.detach(), metric='euclidean')\n",
    "        \n",
    "        x_pred = self.M.T @ z_next\n",
    "        x_next = self.U[:, o_next]\n",
    "        print(self.M.shape, z_next.shape, x_pred.shape)\n",
    "\n",
    "        self.z = z_next\n",
    "        self.M += torch.outer(z_next, x_next).detach()\n",
    "\n",
    "        return z_pred, z_next, x_pred, x_next\n",
    "\n",
    "    def closest_state(self, s, metric='dot'):\n",
    "        if metric == 'dot':\n",
    "            return self.Q[torch.argmax(self.Q.T @ s)]\n",
    "        elif metric == 'euclidean':\n",
    "            s = s.unsqueeze(1)\n",
    "            print(\"Q\", self.Q.shape, s.shape)\n",
    "            print(\"L\", torch.linalg.norm(self.Q.detach() - s, dim=0).shape)\n",
    "            return self.Q[:, torch.argmin(torch.linalg.norm(self.Q.detach() - s, dim=0))]\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "63d33db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: PartiallyObservableCML, dataloader, epochs, norm=False):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    losses = []\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "        loss_over_epoch = 0\n",
    "        for trajectory in dataloader:\n",
    "            model.reset()\n",
    "            \n",
    "            # \"break in\" traj w/o backprop first\n",
    "            for i in range(trajectory.shape[0]):\n",
    "                o, a, o_next = trajectory[0,i,0], trajectory[0,i,1], trajectory[0,i,2]\n",
    "                z_pred, z_next, x_pred, x_next = model(o, a, o_next)\n",
    "\n",
    "                loss1 = loss_fn(z_pred, z_next)\n",
    "                loss2 = loss_fn(x_pred, x_next)\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss1.backward()\n",
    "                optim.step()\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss2.backward()\n",
    "                optim.step()\n",
    "\n",
    "                loss_over_epoch += loss1.item() + loss2.item()\n",
    "\n",
    "            if norm:\n",
    "                model.V.data = model.V / torch.norm(model.V, dim=0)\n",
    "            \n",
    "        losses.append(loss_over_epoch)\n",
    "        print(f\"Epoch {epoch} | Loss: {loss_over_epoch}\")\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0e44462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: Error detected in MvBackward0. Traceback of forward call that caused the error:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/asyncio/base_events.py\", line 638, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/asyncio/base_events.py\", line 1971, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 531, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/_r/m9hbjyhd13bbv3lg031lk0fc0000gn/T/ipykernel_18863/4073022003.py\", line 18, in <module>\n",
      "    loss_record= train_model(model, dataloader, epochs, norm=False)\n",
      "  File \"/var/folders/_r/m9hbjyhd13bbv3lg031lk0fc0000gn/T/ipykernel_18863/3483217236.py\", line 13, in train_model\n",
      "    z_pred, z_next, x_pred, x_next = model(o, a, o_next)\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/calvin/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/var/folders/_r/m9hbjyhd13bbv3lg031lk0fc0000gn/T/ipykernel_18863/3423606575.py\", line 88, in forward\n",
      "    x_pred = self.M.T @ z_next\n",
      " (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1704987093728/work/torch/csrc/autograd/python_anomaly_mode.cpp:118.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([1000]) torch.Size([1000])\n",
      "Q torch.Size([1000, 32]) torch.Size([1000, 1])\n",
      "L torch.Size([32])\n",
      "x False False True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1000, 1000]] is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m PartiallyObservableCML(n_states\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39msize, n_obs\u001b[38;5;241m=\u001b[39mn_obs, n_act\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39mn_actions, embedding_dim\u001b[38;5;241m=\u001b[39mstate_dim)\n\u001b[0;32m---> 18\u001b[0m loss_record\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[94], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, epochs, norm)\u001b[0m\n\u001b[1;32m     20\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m loss_over_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss1\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m loss2\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1000, 1000]] is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "n_nodes = 32\n",
    "batch_size = 32\n",
    "state_dim = 1000\n",
    "epochs = 10\n",
    "n_obs = 10\n",
    "\n",
    "num_desired_trajectories=200\n",
    "# choose env from \"random\", \"small world\" or \"dead ends\"\n",
    "env = GraphEnv(size=n_nodes, n_items=n_obs, env='random', batch_size=batch_size, num_desired_trajectories=num_desired_trajectories)\n",
    "\n",
    "dataset = RandomWalkDataset(env.adj_matrix, batch_size, num_desired_trajectories, n_obs)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "model = PartiallyObservableCML(n_states=env.size, n_obs=n_obs, n_act=env.n_actions, embedding_dim=state_dim)\n",
    "\n",
    "\n",
    "loss_record= train_model(model, dataloader, epochs, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d4d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
